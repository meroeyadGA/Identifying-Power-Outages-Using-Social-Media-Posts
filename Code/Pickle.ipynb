{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle\n",
    "\n",
    "**The purpose of this notebook is to export our model to a pickle file, so we can use the file to build our final product.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/twitter_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18990, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model - Bagging Classifier with decreased dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X and y\n",
    "X = df[['tweet']]\n",
    "y = df['target']\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 19, stratify = y)\n",
    "\n",
    "dropping_list = np.random.choice(list(df[df['target'] == 0].index), 17000, replace = False)\n",
    "\n",
    "df_decrease_class_0 = df.drop(dropping_list)\n",
    "\n",
    "df_decrease_class_0['target'].value_counts()\n",
    "\n",
    "df_decrease_class_0['target'].value_counts(normalize = True)\n",
    "\n",
    "# Assign X and y\n",
    "X = df_decrease_class_0[['tweet']]\n",
    "y = df_decrease_class_0['target']\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 19, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip_accents=Non...\n",
       "                                                          bootstrap_features=False,\n",
       "                                                          max_features=1.0,\n",
       "                                                          max_samples=1.0,\n",
       "                                                          n_estimators=10,\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=None,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'bag__n_estimators': [8, 10], 'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_bag = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = 'english')),\n",
    "    ('bag', BaggingClassifier())\n",
    "])\n",
    "\n",
    "params_pipe_bag = {\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'bag__n_estimators': [8, 10]\n",
    "}\n",
    "\n",
    "gs_pipe_bag = GridSearchCV(pipe_bag, params_pipe_bag, cv = 5)\n",
    "gs_pipe_bag.fit(X_train['tweet'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'bag__n_estimators': 10, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2)}\n",
      "------------------------------------\n",
      "Training score: 0.9691689008042895\n",
      "Testing score: 0.6746987951807228\n",
      "ROC AUC score: 0.6702354767757795\n",
      "Recall score: 0.5847457627118644\n",
      "F1 score: 0.6301369863013699\n"
     ]
    }
   ],
   "source": [
    "print(f'Best params: {gs_pipe_bag.best_params_}')\n",
    "print(\"------------------------------------\")\n",
    "print(f'Training score: {gs_pipe_bag.score(X_train[\"tweet\"], y_train)}')\n",
    "print(f'Testing score: {gs_pipe_bag.score(X_test[\"tweet\"], y_test)}')\n",
    "print(f'ROC AUC score: {roc_auc_score(y_test, gs_pipe_bag.predict(X_test[\"tweet\"]))}')\n",
    "print(f'Recall score: {recall_score(y_test, gs_pipe_bag.predict(X_test[\"tweet\"]))}')\n",
    "print(f'F1 score: {f1_score(y_test, gs_pipe_bag.predict(X_test[\"tweet\"]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the two functions above together, using 'write binary' permissions\n",
    "\n",
    "pickle.dump(gs_pipe_bag, open('../Files/final_model.p', 'wb+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check our work**\n",
    "\n",
    "Let's read in our model and check the score/coefficients.\n",
    "- `pickle.load(file)`: de-serializes the stored object back into a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the above function with open() and 'read binary' permissions to get our model back\n",
    "model_from_pickle = pickle.load(open('../Files/final_model.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6746987951807228\n"
     ]
    }
   ],
   "source": [
    "print(model_from_pickle.score(X_test['tweet'], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64965368, 0.35034632]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_from_pickle.predict_proba([\"power outage is happening, so is blackouts weather is so bad\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing our model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[[0.4 0.6]]\n"
     ]
    }
   ],
   "source": [
    "some_tweet = ['This tweet could be a aggregation of all tweets on twitter mentioniing about blackouts']\n",
    "print(model_from_pickle.predict(some_tweet))\n",
    "print(model_from_pickle.predict_proba(some_tweet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
